# f1_score 지표

## 2022.10.20 batch size 32
best_val_loss: 0.6960667216094436 at epoch 10 <br/>
auc 0.789~
### full sentence
```
              precision    recall  f1-score   support

           0       0.76      0.88      0.81      2144
           1       0.53      0.80      0.64      1121
           2       0.60      0.87      0.71      1293
           3       0.41      0.53      0.46       805
           4       0.50      0.71      0.59       656
           5       0.51      0.56      0.54       502
           6       0.70      0.86      0.77      1569
           7       0.47      0.57      0.52       485
           8       0.53      0.82      0.64      1387
           9       0.46      0.45      0.46       772
          10       0.64      0.89      0.74      2238
          11       0.43      0.34      0.38       399
          12       0.53      0.80      0.64      1479
          13       0.43      0.55      0.49       656
          14       0.43      0.47      0.45       451
          15       0.52      0.76      0.62      1288
          16       0.47      0.68      0.55       884
          17       0.33      0.00      0.01       286
          18       0.00      0.00      0.00       134
          19       0.40      0.28      0.33       455
          20       0.59      0.82      0.69      1497
          21       0.43      0.53      0.47       482
          22       0.71      0.88      0.79      1872
          23       0.67      0.87      0.75      2061
          24       0.49      0.50      0.50       769
          25       0.45      0.14      0.21       183
          26       0.31      0.02      0.03       312
          27       0.46      0.34      0.39       477
          28       0.63      0.86      0.73      1273
          29       0.41      0.54      0.47      1029
          30       0.00      0.00      0.00        89
          31       0.65      0.78      0.70       974
          32       0.47      0.56      0.51       518
          33       0.53      0.72      0.61      1286
          34       0.44      0.45      0.45       695
          35       0.33      0.18      0.23       578
          36       0.35      0.22      0.27       234
          37       0.56      0.39      0.46       467
          38       0.48      0.53      0.50       668
          39       0.47      0.58      0.52       899
          40       0.52      0.80      0.63       896
          41       0.43      0.54      0.48       928
          42       0.61      0.87      0.72      1182
          43       0.52      0.76      0.62       987

   micro avg       0.56      0.70      0.62     39360
   macro avg       0.48      0.56      0.50     39360
weighted avg       0.55      0.70      0.61     39360
 samples avg       0.57      0.72      0.61     39360
 ```
### first sentence
```
              precision    recall  f1-score   support

           0       0.88      0.94      0.91      2253
           1       0.79      0.95      0.86      1582
           2       0.77      0.94      0.85      1574
           3       0.68      0.85      0.75       961
           4       0.69      0.92      0.79       755
           5       0.73      0.82      0.77       548
           6       0.83      0.94      0.88      1608
           7       0.63      0.81      0.71       578
           8       0.73      0.93      0.82      1799
           9       0.67      0.79      0.72       834
          10       0.85      0.94      0.89      2698
          11       0.61      0.69      0.64       400
          12       0.74      0.92      0.82      1822
          13       0.64      0.92      0.76       763
          14       0.67      0.88      0.76       521
          15       0.76      0.94      0.84      1819
          16       0.62      0.84      0.72       990
          17       0.00      0.00      0.00        42
          18       0.62      0.12      0.20        85
          19       0.66      0.75      0.70       417
          20       0.81      0.93      0.87      1841
          21       0.66      0.88      0.75       511
          22       0.87      0.95      0.91      2079
          23       0.86      0.96      0.91      2457
          24       0.65      0.83      0.73      1170
          25       0.47      0.48      0.47        87
          26       0.42      0.25      0.32       195
          27       0.70      0.72      0.71       441
          28       0.80      0.93      0.86      1592
          29       0.55      0.78      0.64      1133
          30       0.00      0.00      0.00         0
          31       0.80      0.93      0.86       987
          32       0.60      0.78      0.68       514
          33       0.73      0.90      0.81      1637
          34       0.62      0.82      0.70       642
          35       0.54      0.59      0.56       532
          36       0.58      0.74      0.65       174
          37       0.66      0.64      0.65       382
          38       0.63      0.74      0.68       698
          39       0.67      0.86      0.75      1092
          40       0.77      0.96      0.85      1168
          41       0.66      0.84      0.74      1115
          42       0.83      0.97      0.90      1494
          43       0.73      0.92      0.82      1289

   micro avg       0.74      0.89      0.81     45279
   macro avg       0.66      0.78      0.71     45279
weighted avg       0.75      0.89      0.81     45279
 samples avg       0.74      0.89      0.80     45279
 ```
### last sentence
```
              precision    recall  f1-score   support

           0       0.87      0.93      0.90      2250
           1       0.77      0.93      0.84      1600
           2       0.71      0.92      0.80      1431
           3       0.63      0.80      0.70       982
           4       0.64      0.91      0.75       711
           5       0.65      0.75      0.69       501
           6       0.79      0.93      0.86      1592
           7       0.59      0.69      0.64       543
           8       0.69      0.92      0.78      1822
           9       0.61      0.67      0.64       806
          10       0.82      0.94      0.87      2543
          11       0.56      0.42      0.48       391
          12       0.68      0.91      0.78      1745
          13       0.56      0.86      0.68       686
          14       0.53      0.82      0.64       456
          15       0.69      0.91      0.78      1780
          16       0.59      0.83      0.69      1086
          17       0.00      0.00      0.00        39
          18       0.00      0.00      0.00        75
          19       0.60      0.66      0.63       421
          20       0.77      0.92      0.83      1820
          21       0.65      0.87      0.74       518
          22       0.86      0.93      0.90      2091
          23       0.82      0.94      0.88      2357
          24       0.63      0.72      0.67      1261
          25       0.59      0.39      0.47        92
          26       0.17      0.00      0.01       229
          27       0.58      0.62      0.60       428
          28       0.77      0.92      0.84      1651
          29       0.52      0.67      0.58       971
          30       0.00      0.00      0.00         1
          31       0.78      0.90      0.84      1006
          32       0.55      0.75      0.63       523
          33       0.68      0.86      0.76      1553
          34       0.56      0.71      0.63       636
          35       0.46      0.48      0.47       570
          36       0.54      0.62      0.58       179
          37       0.61      0.40      0.48       389
          38       0.58      0.66      0.62       654
          39       0.61      0.71      0.66       928
          40       0.72      0.94      0.82      1145
          41       0.62      0.80      0.70      1141
          42       0.79      0.95      0.86      1549
          43       0.69      0.91      0.79      1260

   micro avg       0.70      0.85      0.77     44412
   macro avg       0.60      0.71      0.65     44412
weighted avg       0.70      0.85      0.77     44412
 samples avg       0.70      0.85      0.75     44412
 ```
## 2022.10.21 batch size 32 hidden_act relu 
best_val_loss: 0.783631132286825 at epoch 10 <br/>
auc 0.790~
### full sentence
```
              precision    recall  f1-score   support

           0       0.75      0.88      0.81      2144
           1       0.53      0.81      0.64      1121
           2       0.59      0.86      0.70      1293
           3       0.41      0.56      0.47       805
           4       0.51      0.73      0.60       656
           5       0.48      0.57      0.52       502
           6       0.70      0.86      0.77      1569
           7       0.49      0.61      0.54       485
           8       0.53      0.81      0.64      1387
           9       0.45      0.43      0.44       772
          10       0.64      0.90      0.74      2238
          11       0.45      0.38      0.41       399
          12       0.53      0.81      0.64      1479
          13       0.43      0.56      0.48       656
          14       0.44      0.46      0.45       451
          15       0.51      0.77      0.61      1288
          16       0.47      0.70      0.56       884
          17       0.00      0.00      0.00       286
          18       0.00      0.00      0.00       134
          19       0.41      0.31      0.36       455
          20       0.59      0.82      0.69      1497
          21       0.44      0.57      0.50       482
          22       0.70      0.88      0.78      1872
          23       0.66      0.87      0.75      2061
          24       0.50      0.50      0.50       769
          25       0.45      0.13      0.20       183
          26       0.00      0.00      0.00       312
          27       0.44      0.36      0.39       477
          28       0.63      0.86      0.73      1273
          29       0.42      0.55      0.47      1029
          30       0.00      0.00      0.00        89
          31       0.63      0.79      0.70       974
          32       0.46      0.59      0.52       518
          33       0.51      0.74      0.61      1286
          34       0.41      0.47      0.44       695
          35       0.32      0.15      0.20       578
          36       0.37      0.24      0.29       234
          37       0.63      0.38      0.48       467
          38       0.47      0.54      0.50       668
          39       0.47      0.57      0.52       899
          40       0.54      0.80      0.64       896
          41       0.43      0.55      0.49       928
          42       0.62      0.87      0.72      1182
          43       0.52      0.76      0.62       987

   micro avg       0.56      0.70      0.62     39360
   macro avg       0.47      0.57      0.50     39360
weighted avg       0.54      0.70      0.61     39360
 samples avg       0.56      0.73      0.61     39360
 ```
 ### first sentence
 ```
               precision    recall  f1-score   support

           0       0.81      0.92      0.86      2253
           1       0.74      0.92      0.82      1582
           2       0.71      0.92      0.80      1574
           3       0.63      0.82      0.71       961
           4       0.63      0.88      0.73       755
           5       0.63      0.71      0.67       548
           6       0.77      0.92      0.84      1608
           7       0.60      0.79      0.68       578
           8       0.69      0.90      0.78      1799
           9       0.63      0.73      0.67       834
          10       0.80      0.94      0.86      2698
          11       0.64      0.61      0.63       400
          12       0.70      0.90      0.79      1822
          13       0.55      0.86      0.67       763
          14       0.59      0.79      0.68       521
          15       0.72      0.91      0.80      1819
          16       0.60      0.80      0.68       990
          17       0.00      0.00      0.00        42
          18       0.00      0.00      0.00        85
          19       0.56      0.59      0.57       417
          20       0.77      0.91      0.83      1841
          21       0.57      0.80      0.67       511
          22       0.80      0.92      0.86      2079
          23       0.81      0.93      0.87      2457
          24       0.62      0.73      0.67      1170
          25       0.48      0.33      0.39        87
          26       0.39      0.06      0.10       195
          27       0.62      0.60      0.61       441
          28       0.75      0.91      0.82      1592
          29       0.54      0.74      0.62      1133
          30       0.00      0.00      0.00         0
          31       0.73      0.89      0.80       987
          32       0.56      0.74      0.64       514
          33       0.66      0.89      0.76      1637
          34       0.52      0.74      0.61       642
          35       0.51      0.44      0.47       532
          36       0.55      0.58      0.56       174
          37       0.69      0.57      0.63       382
          38       0.58      0.68      0.62       698
          39       0.61      0.78      0.69      1092
          40       0.70      0.91      0.79      1168
          41       0.61      0.79      0.69      1115
          42       0.77      0.94      0.85      1494
          43       0.68      0.91      0.78      1289

   micro avg       0.69      0.85      0.76     45279
   macro avg       0.60      0.72      0.65     45279
weighted avg       0.69      0.85      0.76     45279
 samples avg       0.70      0.85      0.75     45279
```
### last sentence
```
              precision    recall  f1-score   support

           0       0.80      0.91      0.85      2250
           1       0.70      0.89      0.78      1600
           2       0.65      0.87      0.74      1431
           3       0.58      0.77      0.66       982
           4       0.58      0.79      0.67       711
           5       0.54      0.64      0.59       501
           6       0.74      0.89      0.81      1592
           7       0.57      0.59      0.58       543
           8       0.65      0.88      0.75      1822
           9       0.56      0.62      0.59       806
          10       0.74      0.92      0.82      2543
          11       0.53      0.38      0.44       391
          12       0.66      0.89      0.75      1745
          13       0.50      0.75      0.60       686
          14       0.48      0.66      0.55       456
          15       0.67      0.87      0.75      1780
          16       0.54      0.77      0.64      1086
          17       0.00      0.00      0.00        39
          18       0.00      0.00      0.00        75
          19       0.51      0.51      0.51       421
          20       0.73      0.89      0.80      1820
          21       0.57      0.76      0.65       518
          22       0.80      0.91      0.85      2091
          23       0.77      0.91      0.84      2357
          24       0.58      0.66      0.62      1261
          25       0.62      0.09      0.15        92
          26       0.00      0.00      0.00       229
          27       0.50      0.50      0.50       428
          28       0.72      0.87      0.79      1651
          29       0.46      0.56      0.51       971
          30       0.00      0.00      0.00         1
          31       0.72      0.87      0.79      1006
          32       0.51      0.66      0.58       523
          33       0.61      0.83      0.70      1553
          34       0.49      0.64      0.56       636
          35       0.44      0.34      0.38       570
          36       0.47      0.42      0.45       179
          37       0.66      0.37      0.47       389
          38       0.47      0.56      0.51       654
          39       0.54      0.66      0.60       928
          40       0.66      0.89      0.75      1145
          41       0.54      0.73      0.62      1141
          42       0.72      0.90      0.80      1549
          43       0.61      0.84      0.71      1260

   micro avg       0.65      0.80      0.72     44412
   macro avg       0.55      0.65      0.58     44412
weighted avg       0.65      0.80      0.71     44412
 samples avg       0.65      0.79      0.70     44412
 ```
## 2022.11.1 batch size 32 scheduler CosineAnnealing
모델 학습 현재 진행중<br/>
auc 0.8017517885818805 at val_loss 0.5430061560907181, epoch 24
### full sentence
```
 ---------- CLS ----------
              precision    recall  f1-score   support

           0       0.77      0.89      0.83      2144
           1       0.54      0.81      0.65      1121
           2       0.62      0.86      0.72      1293
           3       0.44      0.56      0.49       805
           4       0.53      0.75      0.62       656
           5       0.52      0.58      0.55       502
           6       0.72      0.85      0.78      1569
           7       0.52      0.64      0.57       485
           8       0.56      0.82      0.67      1387
           9       0.46      0.50      0.48       772
          10       0.67      0.89      0.76      2238
          11       0.45      0.48      0.46       399
          12       0.58      0.79      0.67      1479
          13       0.42      0.57      0.48       656
          14       0.43      0.56      0.48       451
          15       0.53      0.77      0.63      1288
          16       0.53      0.73      0.62       884
          17       0.40      0.05      0.09       286
          18       0.34      0.25      0.29       134
          19       0.44      0.35      0.39       455
          20       0.62      0.81      0.70      1497
          21       0.45      0.55      0.50       482
          22       0.73      0.87      0.80      1872
          23       0.68      0.86      0.76      2061
          24       0.50      0.56      0.53       769
          25       0.32      0.21      0.25       183
          26       0.33      0.19      0.24       312
          27       0.43      0.41      0.42       477
          28       0.65      0.85      0.73      1273
          29       0.47      0.60      0.52      1029
          30       0.50      0.01      0.02        89
          31       0.66      0.77      0.71       974
          32       0.56      0.63      0.59       518
          33       0.54      0.71      0.61      1286
          34       0.46      0.49      0.47       695
          35       0.34      0.28      0.31       578
          36       0.36      0.25      0.29       234
          37       0.58      0.51      0.54       467
          38       0.51      0.57      0.53       668
          39       0.48      0.60      0.53       899
          40       0.55      0.81      0.66       896
          41       0.47      0.57      0.51       928
          42       0.63      0.88      0.74      1182
          43       0.53      0.78      0.63       987

   micro avg       0.58      0.72      0.64     39360
   macro avg       0.52      0.60      0.54     39360
weighted avg       0.57      0.72      0.63     39360
 samples avg       0.59      0.75      0.63     39360
```
### first sentence
```
---------- LSTM first ----------
              precision    recall  f1-score   support

           0       0.90      0.97      0.93      2253
           1       0.85      0.97      0.90      1582
           2       0.84      0.96      0.90      1574
           3       0.80      0.89      0.84       961
           4       0.79      0.95      0.86       755
           5       0.79      0.87      0.83       548
           6       0.88      0.95      0.92      1608
           7       0.76      0.89      0.82       578
           8       0.81      0.96      0.88      1799
           9       0.74      0.87      0.80       834
          10       0.90      0.97      0.93      2698
          11       0.66      0.81      0.73       400
          12       0.82      0.95      0.88      1822
          13       0.70      0.94      0.80       763
          14       0.72      0.95      0.82       521
          15       0.84      0.95      0.89      1819
          16       0.79      0.90      0.84       990
          17       0.70      0.38      0.49        42
          18       0.48      0.69      0.57        85
          19       0.73      0.84      0.78       417
          20       0.88      0.94      0.91      1841
          21       0.76      0.90      0.83       511
          22       0.91      0.96      0.93      2079
          23       0.90      0.97      0.93      2457
          24       0.74      0.90      0.81      1170
          25       0.54      0.77      0.64        87
          26       0.58      0.79      0.67       195
          27       0.74      0.83      0.79       441
          28       0.85      0.95      0.90      1592
          29       0.70      0.89      0.78      1133
          30       0.00      0.00      0.00         0
          31       0.86      0.94      0.90       987
          32       0.76      0.86      0.81       514
          33       0.81      0.94      0.87      1637
          34       0.71      0.90      0.80       642
          35       0.60      0.82      0.70       532
          36       0.62      0.81      0.70       174
          37       0.73      0.82      0.77       382
          38       0.75      0.87      0.80       698
          39       0.76      0.91      0.83      1092
          40       0.83      0.96      0.89      1168
          41       0.75      0.90      0.82      1115
          42       0.88      0.97      0.92      1494
          43       0.81      0.96      0.88      1289

   micro avg       0.81      0.93      0.87     45279
   macro avg       0.75      0.87      0.80     45279
weighted avg       0.82      0.93      0.87     45279
 samples avg       0.82      0.93      0.86     45279
```
### last sentence
```
---------- LSTM last ----------
              precision    recall  f1-score   support

           0       0.91      0.95      0.93      2250
           1       0.84      0.97      0.90      1600
           2       0.78      0.96      0.86      1431
           3       0.76      0.86      0.81       982
           4       0.75      0.96      0.84       711
           5       0.76      0.86      0.81       501
           6       0.87      0.94      0.90      1592
           7       0.75      0.89      0.81       543
           8       0.78      0.95      0.85      1822
           9       0.71      0.85      0.77       806
          10       0.88      0.95      0.91      2543
          11       0.64      0.77      0.70       391
          12       0.81      0.93      0.87      1745
          13       0.65      0.92      0.76       686
          14       0.65      0.93      0.77       456
          15       0.81      0.94      0.87      1780
          16       0.76      0.90      0.83      1086
          17       0.64      0.23      0.34        39
          18       0.55      0.68      0.61        75
          19       0.73      0.79      0.76       421
          20       0.87      0.94      0.91      1820
          21       0.75      0.87      0.80       518
          22       0.91      0.95      0.93      2091
          23       0.88      0.95      0.91      2357
          24       0.73      0.86      0.79      1261
          25       0.56      0.72      0.63        92
          26       0.63      0.68      0.66       229
          27       0.69      0.78      0.73       428
          28       0.83      0.95      0.89      1651
          29       0.66      0.85      0.74       971
          30       0.00      0.00      0.00         1
          31       0.87      0.93      0.90      1006
          32       0.71      0.85      0.78       523
          33       0.80      0.92      0.86      1553
          34       0.75      0.87      0.81       636
          35       0.62      0.73      0.67       570
          36       0.66      0.83      0.74       179
          37       0.71      0.70      0.71       389
          38       0.72      0.85      0.78       654
          39       0.73      0.88      0.80       928
          40       0.79      0.96      0.87      1145
          41       0.75      0.90      0.82      1141
          42       0.84      0.97      0.90      1549
          43       0.75      0.95      0.84      1260

   micro avg       0.80      0.92      0.85     44412
   macro avg       0.73      0.84      0.78     44412
weighted avg       0.80      0.92      0.85     44412
 samples avg       0.80      0.92      0.84     44412
```
 ## 2022.11.2 batch size 32 scheduler CosineAnnealing
 best_val_loss: 0.49686171104953547 at epoch 52 <br/>
AUC score: 0.8035032846176559
Average Train Loss: 0.341327633190155
Average Valid Loss: 0.49686171104953547
### full sentence
```
---------- CLS ----------
              precision    recall  f1-score   support

           0       0.77      0.89      0.83      2144
           1       0.56      0.79      0.66      1121
           2       0.66      0.84      0.74      1293
           3       0.45      0.55      0.49       805
           4       0.57      0.72      0.64       656
           5       0.52      0.63      0.57       502
           6       0.73      0.86      0.79      1569
           7       0.52      0.66      0.58       485
           8       0.60      0.79      0.68      1387
           9       0.44      0.54      0.48       772
          10       0.69      0.88      0.77      2238
          11       0.43      0.52      0.47       399
          12       0.60      0.78      0.68      1479
          13       0.44      0.57      0.50       656
          14       0.46      0.53      0.49       451
          15       0.54      0.75      0.63      1288
          16       0.55      0.71      0.62       884
          17       0.28      0.06      0.10       286
          18       0.33      0.29      0.31       134
          19       0.42      0.42      0.42       455
          20       0.61      0.80      0.70      1497
          21       0.45      0.56      0.50       482
          22       0.73      0.88      0.80      1872
          23       0.69      0.87      0.77      2061
          24       0.54      0.58      0.56       769
          25       0.32      0.21      0.25       183
          26       0.34      0.24      0.28       312
          27       0.43      0.39      0.41       477
          28       0.66      0.85      0.74      1273
          29       0.49      0.61      0.54      1029
          30       0.38      0.03      0.06        89
          31       0.66      0.77      0.71       974
          32       0.60      0.60      0.60       518
          33       0.54      0.73      0.62      1286
          34       0.44      0.50      0.47       695
          35       0.32      0.32      0.32       578
          36       0.36      0.28      0.32       234
          37       0.59      0.53      0.55       467
          38       0.48      0.60      0.53       668
          39       0.49      0.60      0.54       899
          40       0.57      0.77      0.66       896
          41       0.47      0.59      0.52       928
          42       0.65      0.85      0.74      1182
          43       0.56      0.75      0.64       987

   micro avg       0.59      0.72      0.65     39360
   macro avg       0.52      0.61      0.55     39360
weighted avg       0.58      0.72      0.64     39360
 samples avg       0.60      0.75      0.64     39360
 ```
### first sentence
```
---------- LSTM first ----------
              precision    recall  f1-score   support

           0       0.92      0.97      0.95      2253
           1       0.89      0.95      0.92      1582
           2       0.89      0.96      0.92      1574
           3       0.83      0.90      0.86       961
           4       0.84      0.95      0.89       755
           5       0.80      0.91      0.85       548
           6       0.91      0.96      0.93      1608
           7       0.81      0.91      0.86       578
           8       0.87      0.95      0.91      1799
           9       0.75      0.90      0.81       834
          10       0.92      0.97      0.94      2698
          11       0.71      0.89      0.79       400
          12       0.87      0.96      0.91      1822
          13       0.78      0.93      0.85       763
          14       0.81      0.93      0.87       521
          15       0.89      0.94      0.91      1819
          16       0.85      0.91      0.88       990
          17       0.68      0.55      0.61        42
          18       0.61      0.84      0.71        85
          19       0.73      0.88      0.80       417
          20       0.89      0.95      0.92      1841
          21       0.85      0.89      0.87       511
          22       0.91      0.97      0.94      2079
          23       0.91      0.98      0.94      2457
          24       0.82      0.90      0.86      1170
          25       0.65      0.76      0.70        87
          26       0.68      0.78      0.73       195
          27       0.78      0.85      0.81       441
          28       0.89      0.96      0.92      1592
          29       0.79      0.89      0.83      1133
          30       0.00      0.00      0.00         0
          31       0.89      0.94      0.91       987
          32       0.82      0.86      0.84       514
          33       0.84      0.96      0.89      1637
          34       0.75      0.89      0.81       642
          35       0.72      0.81      0.76       532
          36       0.70      0.82      0.75       174
          37       0.79      0.85      0.82       382
          38       0.78      0.91      0.84       698
          39       0.80      0.91      0.85      1092
          40       0.87      0.94      0.91      1168
          41       0.80      0.92      0.86      1115
          42       0.89      0.97      0.93      1494
          43       0.86      0.95      0.90      1289

   micro avg       0.86      0.94      0.89     45279
   macro avg       0.80      0.88      0.84     45279
weighted avg       0.86      0.94      0.90     45279
 samples avg       0.86      0.94      0.89     45279
```
### last sentence
```
---------- LSTM last ----------
              precision    recall  f1-score   support

           0       0.92      0.96      0.94      2250
           1       0.91      0.95      0.93      1600
           2       0.87      0.94      0.90      1431
           3       0.81      0.87      0.84       982
           4       0.83      0.94      0.88       711
           5       0.78      0.89      0.83       501
           6       0.90      0.94      0.92      1592
           7       0.82      0.88      0.85       543
           8       0.88      0.95      0.91      1822
           9       0.74      0.87      0.80       806
          10       0.90      0.97      0.93      2543
          11       0.70      0.84      0.76       391
          12       0.86      0.95      0.90      1745
          13       0.80      0.87      0.83       686
          14       0.77      0.90      0.83       456
          15       0.87      0.94      0.91      1780
          16       0.85      0.91      0.88      1086
          17       0.77      0.51      0.62        39
          18       0.60      0.83      0.70        75
          19       0.73      0.81      0.77       421
          20       0.89      0.95      0.92      1820
          21       0.82      0.89      0.85       518
          22       0.91      0.96      0.94      2091
          23       0.89      0.96      0.92      2357
          24       0.80      0.89      0.85      1261
          25       0.68      0.72      0.70        92
          26       0.66      0.78      0.72       229
          27       0.75      0.81      0.78       428
          28       0.88      0.95      0.92      1651
          29       0.75      0.86      0.80       971
          30       0.00      0.00      0.00         1
          31       0.90      0.92      0.91      1006
          32       0.79      0.83      0.81       523
          33       0.82      0.95      0.88      1553
          34       0.78      0.87      0.82       636
          35       0.68      0.84      0.75       570
          36       0.72      0.82      0.77       179
          37       0.78      0.79      0.79       389
          38       0.77      0.89      0.83       654
          39       0.78      0.91      0.84       928
          40       0.86      0.94      0.90      1145
          41       0.80      0.91      0.85      1141
          42       0.88      0.97      0.92      1549
          43       0.86      0.93      0.89      1260

   micro avg       0.85      0.92      0.88     44412
   macro avg       0.79      0.86      0.82     44412
weighted avg       0.85      0.92      0.88     44412
 samples avg       0.85      0.93      0.88     44412
 ```
## 2022.11.26 batch size 32 scheduler CosineAnnealing LSTM num_layers=2
best_val_loss: 0.48704139632024585 at epoch 55 <br/>
AUC score: 0.8030956216199673
Average Train Loss: 0.3462992896795273
Average Valid Loss: 0.48704139632024585
### full sentence
```
---------- CLS ----------
              precision    recall  f1-score   support

           0       0.78      0.88      0.83      2144
           1       0.55      0.81      0.66      1121
           2       0.64      0.86      0.73      1293
           3       0.44      0.56      0.50       805
           4       0.54      0.73      0.62       656
           5       0.53      0.56      0.54       502
           6       0.75      0.83      0.79      1569
           7       0.51      0.65      0.57       485
           8       0.59      0.81      0.68      1387
           9       0.44      0.53      0.48       772
          10       0.68      0.89      0.77      2238
          11       0.46      0.46      0.46       399
          12       0.60      0.77      0.68      1479
          13       0.45      0.56      0.50       656
          14       0.45      0.51      0.48       451
          15       0.53      0.78      0.63      1288
          16       0.53      0.71      0.61       884
          17       0.29      0.06      0.10       286
          18       0.34      0.25      0.29       134
          19       0.45      0.38      0.41       455
          20       0.61      0.82      0.70      1497
          21       0.47      0.57      0.51       482
          22       0.74      0.88      0.80      1872
          23       0.69      0.86      0.77      2061
          24       0.56      0.55      0.56       769
          25       0.34      0.16      0.22       183
          26       0.38      0.23      0.28       312
          27       0.45      0.40      0.42       477
          28       0.66      0.86      0.74      1273
          29       0.49      0.60      0.54      1029
          30       0.33      0.01      0.02        89
          31       0.67      0.77      0.72       974
          32       0.58      0.62      0.60       518
          33       0.54      0.71      0.61      1286
          34       0.45      0.49      0.47       695
          35       0.35      0.32      0.33       578
          36       0.35      0.24      0.29       234
          37       0.58      0.52      0.55       467
          38       0.49      0.58      0.53       668
          39       0.50      0.62      0.55       899
          40       0.57      0.78      0.66       896
          41       0.49      0.58      0.53       928
          42       0.65      0.86      0.74      1182
          43       0.56      0.74      0.64       987

   micro avg       0.59      0.71      0.65     39360
   macro avg       0.52      0.60      0.55     39360
weighted avg       0.58      0.71      0.64     39360
 samples avg       0.60      0.74      0.64     39360
```
### first sentence
```
---------- LSTM first ----------
              precision    recall  f1-score   support

           0       0.94      0.96      0.95      2253
           1       0.87      0.97      0.92      1582
           2       0.87      0.98      0.92      1574
           3       0.85      0.88      0.86       961
           4       0.84      0.95      0.89       755
           5       0.81      0.88      0.85       548
           6       0.93      0.96      0.94      1608
           7       0.83      0.91      0.87       578
           8       0.87      0.96      0.91      1799
           9       0.80      0.88      0.83       834
          10       0.92      0.97      0.94      2698
          11       0.77      0.84      0.80       400
          12       0.90      0.94      0.92      1822
          13       0.79      0.92      0.85       763
          14       0.81      0.93      0.86       521
          15       0.86      0.96      0.90      1819
          16       0.81      0.93      0.87       990
          17       0.75      0.57      0.65        42
          18       0.66      0.81      0.73        85
          19       0.80      0.83      0.82       417
          20       0.90      0.95      0.92      1841
          21       0.84      0.89      0.87       511
          22       0.94      0.96      0.95      2079
          23       0.92      0.97      0.94      2457
          24       0.83      0.90      0.86      1170
          25       0.70      0.62      0.66        87
          26       0.72      0.77      0.75       195
          27       0.84      0.81      0.82       441
          28       0.90      0.96      0.93      1592
          29       0.81      0.89      0.85      1133
          30       0.00      0.00      0.00         0
          31       0.91      0.94      0.92       987
          32       0.80      0.89      0.85       514
          33       0.85      0.95      0.89      1637
          34       0.77      0.90      0.83       642
          35       0.73      0.79      0.76       532
          36       0.76      0.82      0.78       174
          37       0.80      0.84      0.82       382
          38       0.81      0.89      0.85       698
          39       0.82      0.91      0.87      1092
          40       0.87      0.95      0.91      1168
          41       0.82      0.90      0.86      1115
          42       0.90      0.98      0.94      1494
          43       0.86      0.96      0.91      1289

   micro avg       0.86      0.93      0.90     45279
   macro avg       0.81      0.87      0.84     45279
weighted avg       0.87      0.93      0.90     45279
 samples avg       0.87      0.94      0.89     45279
```
### last sentence
```
---------- LSTM last ----------
              precision    recall  f1-score   support

           0       0.93      0.96      0.94      2250
           1       0.88      0.96      0.92      1600
           2       0.85      0.97      0.90      1431
           3       0.83      0.88      0.86       982
           4       0.82      0.95      0.88       711
           5       0.83      0.89      0.86       501
           6       0.92      0.94      0.93      1592
           7       0.82      0.91      0.86       543
           8       0.87      0.96      0.91      1822
           9       0.76      0.88      0.82       806
          10       0.91      0.97      0.94      2543
          11       0.73      0.83      0.78       391
          12       0.90      0.94      0.92      1745
          13       0.77      0.89      0.83       686
          14       0.79      0.89      0.84       456
          15       0.85      0.95      0.90      1780
          16       0.83      0.91      0.86      1086
          17       0.63      0.67      0.65        39
          18       0.57      0.77      0.66        75
          19       0.80      0.81      0.80       421
          20       0.89      0.95      0.92      1820
          21       0.83      0.88      0.85       518
          22       0.94      0.96      0.95      2091
          23       0.91      0.96      0.94      2357
          24       0.84      0.90      0.86      1261
          25       0.76      0.72      0.74        92
          26       0.70      0.78      0.74       229
          27       0.79      0.82      0.80       428
          28       0.87      0.96      0.91      1651
          29       0.77      0.88      0.82       971
          30       0.00      0.00      0.00         1
          31       0.91      0.93      0.92      1006
          32       0.77      0.88      0.82       523
          33       0.86      0.94      0.90      1553
          34       0.80      0.88      0.84       636
          35       0.71      0.82      0.76       570
          36       0.79      0.81      0.80       179
          37       0.73      0.86      0.79       389
          38       0.79      0.88      0.83       654
          39       0.79      0.90      0.84       928
          40       0.86      0.95      0.90      1145
          41       0.86      0.87      0.87      1141
          42       0.88      0.98      0.92      1549
          43       0.85      0.94      0.90      1260

   micro avg       0.86      0.93      0.89     44412
   macro avg       0.80      0.87      0.83     44412
weighted avg       0.86      0.93      0.89     44412
 samples avg       0.86      0.93      0.88     44412
 ```
